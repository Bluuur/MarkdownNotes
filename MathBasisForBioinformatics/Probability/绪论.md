# 概率论重要知识点回顾

## 小概率原理

### 小概率事件

统计学上一般把$P\leq0.05$或$P\leq0.01$的事件称为小概率事件

### 小概率原理

小概率事件在一次试验中几乎不可能发生。利用该原理可对科研资料进行假设检验。

## 大数定律与中心极限定理

研究大量的随机现象，常常采用极限形式， 由此导致对极限定理进行研究.

极限定理最重要的有两种:

+   大数定理
+   中心极限定理

### 大数定理

大量重复试验的平均结果的稳定性

+   定理1:当样本无限地增大，事件发生的频率将与概率趋于一致。
+   定理2:无穷多个独立地随机变量(样本值),如果具有相同的数学期望时,则这些变量(来自同一总体)的平均数将趋近于它们的数学期望.

>   作用：建立了频率与概率之间的统计关系，使得我们能够把概率论的原理应用于统计学的基础。

#### 切比雪夫不等式

对于 $\mathrm{r.v.}\ X, EX$ 和 $DX$ 存在, 则 $\forall\varepsilon>0$ 都有:
$$
P\left( \left| X-EX\right|\geq\varepsilon\right)\leq\frac{DX}{\varepsilon^2}
$$

>   $\varepsilon$是任意正数
>   $\left| X-EX\right|$ 是变量到期望的距离
>
>   不等式左边是随机变量落在{期望附近区域(由$\varepsilon$划分)}的概率
>   右边表示方差与这个区域相对大的比值
>   也就是说,这个区域越大,落在区域外的概率绝对会越小
>
>   *不等式右边分子是$\varepsilon^2$的原因是为了保证量纲和谐,因为方差的量纲也有平方

#### 切比雪夫大数定律

**收敛**:$a_n\to a, \forall \varepsilon > 0 , \exist N>0, \text{when}\ n>N,|a_n-a|<\varepsilon$

>   存在某一项其后的**全部项**落在区域内

**依概率收敛**: $x_n \stackrel{P}{\to} a$
$$
\lim_{n\to \infty}P \left \{ |X_n - a| < \varepsilon \right \} = 1
$$

>   依概率收敛允许有不落在范围内的

>   收敛比依概率收敛更严格

##### 定义

对于$X_1,X_2,\cdots,X_n$这$n$个不相关的变量,$EX_i$和$DX_i$都存在,方差有界,$DX_i\leq M,\forall \varepsilon>0$
$$
\lim_{n\to \infty}P \left\{ \left| \frac{1}{n}\sum_{i=1}^{n}X_i-\frac{1}{n}\sum_{i=1}^{n}EX_i \right|<\varepsilon \right \}=1
$$


#### 切比雪夫($Chebyshev$)定理的特殊情况

设随机变量 $X_1,X_2,\cdots,X_n$相互独立,且具有相同的数学期望和方差$E(X_k)=\mu,D(X_k)=\sigma^2,(k=1,2,\cdots),$做前$n$个随机变量的算数平均$Y_{n}=\frac{1}{n} \sum_{k=1}^{n} X_{k}$,则对于任意整数$\varepsilon$,有:
$$
\begin{aligned}
&\lim _{n \rightarrow \infty} P\left\{\left|Y_{n}-\mu\right|<\varepsilon\right\} \\
=&\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}\\=&1
\end{aligned}
$$

#### 伯努利大数定理

设$\mu_n$是$n$重伯努利试验中事件$A$发生的次数,每次试验中$A$发生的概率为$p(0<p<1)$,则对任意$\varepsilon>0,$有:

>   伯努利试验服从二项分布

$$
\lim _{n \rightarrow \infty} P\left\{\left|\frac{\mu_{n}}{n}-p\right|>\varepsilon\right\}=0
$$
即:
$$
\frac{\mu_{n}}{n} \stackrel{P}{\longrightarrow} p
$$

>   注:当$n$很大时,事件发生的频率会“靠近”其概率.
>
>   “靠近”指的是依概率收敛

#### 辛钦定理

>   独立同分布 $independently\ identically\ distribution\quad i.i.d.$

设随机变量 $X_1,X_2,\cdots,X_n$ 相互独立,服从同一分布,且具有相同的数学期望 $E(X_k)=\mu(k=1,2,\cdots)$ ,则对于任意 $\varepsilon>0$ 有:
$$
\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1
$$

>   说明:伯努利大数定理是辛钦定理的特殊情况.$n$个随机变量的算术平均值以概率收敛于算术平均值的数学期望.

### 独立同分布情形的中心极限定理

设随机变量序列 $\{X_n,n\geq1\}$ 满足:

+   相互独立
+   同分布
+   期望 $EX_n=\mu$ 和方差 $DX_n=\sigma^2$ 都存在

对于任意的$x\in R$,有
$$
\large \lim_{x\to \infty}P\left(\frac{\sum_{i=1}^{n}-n\mu}{\sqrt{n}\sigma}\leq x\right)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}\mathrm{d}t=\Phi(x)
$$
设$\xi\sim N(0,1),$则上式可重新写成
$$
\large \lim _{n \rightarrow \infty} P\left(\frac{\sum_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma} \leq x\right)=P(\xi \leq x)
$$
也就是说,当 $n\to\infty$ 时$,\Large \mathrm{r.v.}\frac{\sum_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma}$与标准正态 $\mathrm{r.v.}\ \xi$ 所起的作用越来越相当,于是我们称$\Large \frac{\sum_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma}$**渐进标准正态**

