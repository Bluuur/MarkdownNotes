# 生物信息学数学基础

## Table of Contents

[toc]

# 知识点回顾

## 小概率原理

### 小概率事件

统计学上一般把 $P\leq0.05$ 或 $P\leq0.01$ 的事件称为小概率事件

### 小概率原理

小概率事件在一次试验中几乎不可能发生. 利用该原理可对科研资料进行假设检验. 

## 大数定律与中心极限定理

研究大量的随机现象，常常采用极限形式， 由此导致对极限定理进行研究.

极限定理最重要的有两种:

+   大数定理
+   中心极限定理

### 大数定理

大量重复试验的平均结果的稳定性

>   平均结果: 期望

+   定理1:当样本无限地增大，事件发生的频率将与概率趋于一致。
+   定理2:无穷多个独立地随机变量(样本值),如果具有相同的数学期望时,则这些变量(来自同一总体)的平均数将趋近于它们的数学期望.

>   作用：建立了频率与概率之间的统计关系，使得我们能够把概率论的原理应用于统计学的基础。

#### 切比雪夫不等式

对于 $\mathrm{r.v.}\ X, EX$ 和 $DX$ 存在, 则 $\forall\varepsilon>0$ 都有:
$$
P\left( \left| X-EX\right|\geq\varepsilon\right)\leq\frac{DX}{\varepsilon^2}
$$

>   $\varepsilon$是任意正数
>   $\left| X-EX\right|$ 是变量到期望的距离
>
>   不等式左边是随机变量落在{期望附近区域(由 $\varepsilon$ 划分)}的概率
>   右边表示方差与这个区域相对大的比值
>   也就是说, 这个区域越大, 落在区域外的概率绝对会越小( 小于 $\frac{DX}{\varepsilon^2}$ )
>
>   *不等式右边分子是 $\varepsilon^2$ 的原因是为了保证量纲和谐, 因为方差的量纲也有平方

#### 切比雪夫大数定律

---

关于收敛与依概率收敛:

**收敛**: $a_n\to a, \forall \varepsilon > 0 , \exist N>0, \text{when}\ n>N,|a_n-a|<\varepsilon$

>   存在某一项其后的**全部项**落在以 $\varepsilon$ 为半径的区域内

**依概率收敛**: $x_n \stackrel{P}{\to} a$
$$
\lim_{n\to \infty}P \left \{ |X_n - a| < \varepsilon \right \} = 1
$$

>   依概率收敛允许有不落在范围内的
>   收敛比依概率收敛更严格

---

设随机变量 $X_1,X_2,\cdots,X_n$ **相互独立, 服从同一分布**(独立同分布), 设 $X_i=\begin{cases}1\quad 发生\\0\quad 不发生\end{cases}$ , 则:
$$
\begin{aligned}
&期望:EX_i = P\\
&方差:DX_i=P(1-P)\\
&发生次数:m_n=\sum\limits_{i=1}^nX_i\\
&频率:\frac{m_n}{n}=\frac{1}{n}\sum\limits_{i=1}^nX_i\\
&概率:P=E\left(\frac{1}{n}\sum\limits_{i=1}^nX_i\right)\\
&\qquad\ \quad=\frac{1}{n}\sum\limits_{i=1}^nEX_i\\
\\
&有:\\
&\lim_{n\to \infty}P \left\{ \left| \frac{1}{n}\sum_{i=1}^{n}X_i-\frac{1}{n}\sum_{i=1}^{n}EX_i \right|<\varepsilon \right \}=1
\end{aligned}
$$

> **频率依概率收敛于概率**

---

##### 定义

对于 $X_1,X_2,\cdots,X_n$ 这 $n$ 个**不相关的变量**, $EX_i$ (每个变量的期望)和 $DX_i$ (每个变量的方差)都存在, 方差有界, $DX_i\leq M,\forall \varepsilon>0$
$$
\lim_{n\to \infty}P \left\{ \left| \frac{1}{n}\sum_{i=1}^{n}X_i-\frac{1}{n}\sum_{i=1}^{n}EX_i \right|<\varepsilon \right \}=1
$$

>   注意: 切比雪夫大数定律没有要求这些变量独立同分布
>
>   均值: $\frac{1}{n}\sum\limits_{i=1}^{n}X_i$
>
>   期望的均值: $\frac{1}{n}\sum\limits_{i=1}^{n}EX_i$
>
>   **均值依概率收敛于期望的均值**

#### 切比雪夫($Chebyshev$)定理的特殊情况 (推论)

设随机变量 $X_1,X_2,\cdots,X_n$ 独立同分布, 且具有相同的数学期望和方差$E(X_k)=\mu,D(X_k)=\sigma^2,(k=1,2,\cdots),$ 做前 $n$ 个随机变量的算数平均 $Y_{n}=\frac{1}{n} \sum\limits_{k=1}^{n} X_{k}$, 则对于任意整数 $\varepsilon$, 有:
$$
\begin{aligned}
&\lim _{n \rightarrow \infty} P\left\{\left|Y_{n}-\mu\right|<\varepsilon\right\} \\
=&\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}\\=&1
\end{aligned}
$$

#### 伯努利大数定理

设 $\mu_n$ 是 $n$ 重伯努利试验中事件 $A$ 发生的次数, 每次试验中 $A$ 发生的概率为 $p(0<p<1)$, 则对任意 $\varepsilon>0,$ 有:

>   伯努利试验服从二项分布

$$
\lim _{n \rightarrow \infty} P\left\{\left|\frac{\mu_{n}}{n}-p\right|>\varepsilon\right\}=0
$$

即:
$$
\frac{\mu_{n}}{n} \stackrel{P}{\longrightarrow} p
$$

>   注:当$n$很大时,事件发生的频率会「靠近」其概率.
>   当 $n$ 趋于 无穷 时, 事件的频率 会 依概率收敛 于 事件的概率
>
>   「靠近」指的是依概率收敛

#### 辛钦大数定理

>   独立同分布 $independently\ identically\ distribution\quad i.i.d.$

设随机变量 $X_1,X_2,\cdots,X_n$ **相互独立, 服从同一分布**(独立同分布), 且具有相同的数学期望 (对方差无要求) $E(X_k)=\mu(k=1,2,\cdots)$ ,则对于任意 $\varepsilon>0$ 有:
$$
\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1
$$

>   说明: 伯努利大数定理是辛钦定理的特殊情况. $n$ 个随机变量的算术平均值以概率收敛于算术平均值的数学期望.
>
>   **均值依概率收敛于期望**
>
>   多次测量取平均值可以减小误差(接近真实值(期望))

---

以上三个大数定律条件越来越弱, 证明越来越困难

## 中心极限定理

现象是受大量相互独立的因素影响的

大量独立同分布的变量和的极限分布是正态分布

### 独立同分布情形的中心极限定理

设随机变量序列 $\{X_n,n\geq1\}$ 满足:

+   相互独立
+   同分布
+   期望 $EX_n=\mu$ 和方差 $DX_n=\sigma^2(0<\sigma^2<+\infty)$ 都存在

对于任意的$x\in R$,有
$$
\large \lim_{x\to \infty}P\left(\frac{\sum\limits_{i=1}^{n}-n\mu}{\sqrt{n}~\sigma}\leq x\right)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}\mathrm{d}t=\Phi(x)
$$
设$\xi\sim N(0,1),$则上式可重新写成
$$
\large \lim _{n \rightarrow \infty} P\left(\frac{\sum\limits_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma} \leq x\right)=P(\xi \leq x)
$$
也就是说,当 $n\to\infty$ 时$,\Large \mathrm{r.v.}\frac{\sum\limits_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma}$与标准正态 $\mathrm{r.v.}\ \xi$ 所起的作用越来越相当, 于是我们称$\Large \frac{\sum\limits_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma}$**渐进标准正态**

> ### 正态分布
>
> $$
> \varphi(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{\Large-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\qquad -\infty<x<+\infty
> $$
> 消去 $\sigma,\mu$ 时就是标准正态分布, 也就是 $\sigma = 1, \mu= 0$ , $\sigma$ 是期望, $\mu$ 是标准差
> $$
> \varphi_{0}(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^{2}}{2}}
> $$
>
> ---
>
> 正态分布标准化:
>
> 概率密度函数:
> $$
> \varphi(x)=\frac{1}{\sigma} \varphi_{0}\left(\frac{x-\mu}{\sigma}\right)
> $$
> 概率分布:
> $$
> \Phi(x)=\Phi_{0}\left(\frac{x{-\mu}}{\sigma}\right)
> $$
>
> ---
>
> ### 均匀分布
>
> $X\sim U(a,b)$
> $$
> f(x)=\left\{\begin{array}{cc}
> \frac{1}{b-a} & a \leqslant x \leqslant b \\
> 0 & \text { Other }
> \end{array}\right.
> $$
>
> >   区间上的积分为1
>
> $$
> EX=\frac{b+a}{2}\quad DX=\frac{(b-a)^2}{12}
> $$
>
> ---
>
> ### 指数分布
>
> $$
> f(x)=\left\{\begin{array}{cc}
> \lambda e^{-\lambda x} & x>0 \\
> 0  & x \leqslant 0
> \end{array}\right.
> $$
>
> >   $\lambda>0  \quad X \sim \operatorname{Exp}(\lambda)$
>
> $$
> EX=\frac{1}{\lambda}\quad DX=\frac{1}{\lambda^2}
> $$
>
> > 无记忆性 寿命
> > 自身的每一部分都与自身相似

#### 独立同分布中心极限定理的应用

**每日有顾客 $100$ 人, 消费金额 $[0,60]$, 每个人的购买金额之间相互独立, 求日销售额超过 $3500$ 元的概率**

解:
$$
\begin{aligned}
&设第~i~人购买金额为~X_i\\
EX_i&=30\quad DX_i=\frac{60^2}{12}=300\\
&即求\sum_{i=1}^{100}X_i>3500\\
&\frac{\sum X_i-3000}{100\sqrt{3}}\sim N(0,1)\\
P\left( \sum X_i>3500 \right)&=1-P\left( \sum X_i\leq3500 \right)\\
&=1-P\left(\frac{\sum X_i-3000}{100\sqrt{3}}\leq\frac{3500-3000}{100\sqrt{3}}\right )\\&=1-\Phi_0(2.887)\\
&=0.002
\end{aligned}
$$

> + 一般解题步骤
>   + 求期望与方差
>   + 标准化
>   + 求正态分布

### De Moivre - Laplace 中心极限定理

是独立同分布中心极限定理的特例

随机变量 $Y\sim B(n,p)$ (服从二项分布)
$$
\lim _{n \rightarrow \infty} P\left(\frac{Y_{n}-n p}{\sqrt{n p(1-p)}} \leqslant x\right)=\Phi_{0}(x)
$$

> $$
> Y_n=\sum_{i=1}^{n}X_i\quad X_i=\begin{cases}1,\quad 发生\\0,\quad未发生\end{cases}
> $$

> $EX_i=p\quad DX_i=p(1-p)$

用正态分布近似二项分布, 因为二项分布计算麻烦

---

应用:

**保险, 每人死亡概率为 $0.005$, 共 $10000$ 人投保, 求死亡人数不超过 $70$ 人的概率**
$$
\begin{aligned}
&解: 设死亡人数为X\\
P(X\leq70)&=\sum_{k=0}^{70}C_{10000}^k\cdot0.005^k\cdot0.995^{10000-k}\\
&使用正态分布近似:\\
P(X\leq70)&=P\left(\frac{X-np}{\sqrt{np(1-p)}}\leq\frac{70-np}{\sqrt{np(1-p)}}\right)\\
&=\Phi_0(2.84)\\
&=0.9977
\end{aligned}
$$
如果需要计算死亡 $k$ 人概率:
$$
\begin{aligned}
P(X=k)&=P(k-\frac{1}{2}<X<k+\frac{1}{2})\\
&=P\left( \frac{k-\frac{1}{2}-np}{\sqrt{np(1-p)} } < \frac{X-np}{\sqrt{np(1-p)}} < \frac{k+\frac{1}{2}-np}{\sqrt{np(1-p)} } \right)\\
&=\Phi_0\left( \frac{k+\frac{1}{2}-np}{\sqrt{np(1-p)} } \right) - \Phi_0\left(\frac{k-\frac{1}{2}-np}{\sqrt{np(1-p)} }\right)
\end{aligned}
$$

> 关于二项分布的近似
>
> + $n$ 大, $np$ 大小适中(小于 $10$)      使用泊松分布近似
> + $n$ 大, $np$ 也很大      使用正态分布近似

# Chap 5 样本及抽样分布

## 总体

研究对象的全体

> 总体是一个带有确定概率分布的随机变量

## 样本

抽自总体的若干个体

### 样本容量

样本中个体的个数

## 简单随机样本 

样本 $X_1,\cdots,X_n$ 满足:

+ 它们相互独立
+ 它们与总体具有相同分布

则称 $X_1,\cdots,X_n$ 为简单随机样本. 它们的观测值记为 $x_1,\cdots,x_n$, 称为样本值

### 特点

独立, 同分布(具有代表性, 代表总体)

### 获取方式

有放回抽样

> 统计是从手中已有的资料(样本观察值), 去推断总体的情况(总体分布)

## 样本的联合分布

样本 $X_1,\cdots,X_n$ 是一个 $n$ 维随机变量

离散总体 $X$ 的概率分布为: 

